# Knowledge Search Workflow

Answer user questions using Nablarch 6 knowledge base.

## Input

User's query (natural language)

## Output

Japanese answer with knowledge base citations

## Overview

This workflow orchestrates keyword-search and section-judgement workflows to find relevant knowledge, then generates a comprehensive answer.

## Steps

### Step 1: Execute Keyword Search

**Workflow**: `workflows/keyword-search.md`

**Action**: Execute keyword-search workflow to find candidate sections.

1. Read `workflows/keyword-search.md`
2. Follow the workflow to extract keywords and find candidate sections

**Output**: JSON with candidate sections from keyword-search workflow

### Step 2: Execute Section Judgement

**Workflow**: `workflows/section-judgement.md`

**Action**: Execute section-judgement workflow to filter relevant sections.

1. Read `workflows/section-judgement.md`
2. Follow the workflow to judge and filter sections by relevance

**Output**: JSON with relevant sections (High and Partial relevance)

### Step 3: Generate Answer

**Action**: Synthesize answer from relevant sections.

1. **Read section content**:
   ```bash
   jq -r '.sections[<section_id>]' <file_path>
   ```

2. **Analyze sections**:
   - Identify main concepts
   - Extract code examples
   - Note configuration requirements
   - Identify best practices and cautions

3. **Structure answer** in Japanese:

```markdown
## æ¦‚è¦
<High-relevance sections summary>

## å®Ÿè£…æ–¹æ³•
<Step-by-step instructions from sections>

## ã‚³ãƒ¼ãƒ‰ä¾‹
<Code examples from sections>

## é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
- âœ… <Must-do items>
- âš ï¸ <Cautions>
- ğŸ’¡ <Tips>

## å‚è€ƒ
- <Knowledge file citations with section IDs>
```

4. **Validation**:
   - Answer uses ONLY information from knowledge files
   - All statements are supported by section content
   - Code examples are copied directly (not modified)
   - Citations include file path and section ID

**Output**: Formatted answer in Japanese

## Error Handling

**No candidate sections found** (Step 1 returns empty):
- Message: "ã“ã®æƒ…å ±ã¯çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
- List extracted keywords
- Show available categories from index.toon

**No relevant sections after judgement** (Step 2 returns empty):
- Message: "è©²å½“ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
- List candidate sections that were checked
- Suggest broadening search terms

## Important Notes

**Knowledge-only constraint**:
- Use ONLY information from knowledge files
- DO NOT supplement with external knowledge or LLM training data
- If information is missing, explicitly state: "ã“ã®æƒ…å ±ã¯çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"

**Citation format**:
- Format: `[ãƒ•ã‚¡ã‚¤ãƒ«å](knowledge/path/to/file.json#section-id)`
- Example: `[UniversalDao](knowledge/features/libraries.json#universal-dao-overview)`

**Tool call efficiency**:
- Total tool calls: ~5-10 calls
  - Step 1 (Keyword Search): 2-3 calls (Read index.toon, extract sections with jq)
  - Step 2 (Section Judgement): 1-3 calls (Read section content with jq)
  - Step 3 (Answer Generation): 1-2 calls (Read final sections, generate answer)
- Agent performs semantic analysis in memory without additional tool calls
- Scripts are only used for mechanical extraction (jq for JSON parsing)
